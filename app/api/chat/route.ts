// ğŸ“‚ app/api/chat/route.ts
import { NextResponse } from 'next/server';

// Optionnel: exÃ©cuter sur lâ€™Edge si tu veux un dÃ©marrage plus vif

// ---------- Types cÃ´tÃ© client ----------
type ChatMessage = {
  text: string; // contenu du message
  isUser: boolean; // true si lâ€™utilisateur, false si lâ€™assistant
  timestamp: string; // ISO string
};
type ChatRequestBody = {
  messages: ChatMessage[];
};

// ---------- Types minimalistes pour OpenAI ----------
type OpenAIChatMessage = { content?: string };
type OpenAIChoice = { message?: OpenAIChatMessage };
type OpenAIResponse = { choices?: OpenAIChoice[] };

// ---------- Type guards et utils sÃ»rs ----------
function isRecord(u: unknown): u is Record<string, unknown> {
  return typeof u === 'object' && u !== null;
}
function isChatMessage(u: unknown): u is ChatMessage {
  return (
    isRecord(u) &&
    typeof u.text === 'string' &&
    typeof u.isUser === 'boolean' &&
    typeof u.timestamp === 'string'
  );
}
function isChatRequestBody(u: unknown): u is ChatRequestBody {
  return isRecord(u) && Array.isArray(u.messages) && u.messages.every(isChatMessage);
}
function isOpenAIResponse(u: unknown): u is OpenAIResponse {
  return isRecord(u) && Array.isArray(u.choices);
}
function extractOpenAIReply(u: OpenAIResponse): string | null {
  const first = u.choices?.[0];
  if (!first || !isRecord(first)) return null;
  const msg = first.message;
  return isRecord(msg) && typeof msg.content === 'string' ? msg.content : null;
}

// ---------- ParamÃ©trage ----------
const MODEL = process.env.OPENAI_MODEL ?? 'gpt-3.5-turbo'; // mets ici un modÃ¨le rÃ©cent si dispo
const PROJECT = process.env.OPENAI_PROJECT_ID ?? '';
const API_KEY = process.env.OPENAI_API_KEY ?? '';
const TEMPERATURE = Number.isFinite(Number(process.env.OPENAI_TEMPERATURE))
  ? Number(process.env.OPENAI_TEMPERATURE)
  : 0.7;

// Limites raisonnables pour Ã©viter les abus / surprises de coÃ»ts
const MAX_HISTORY = 10; // derniers messages conservÃ©s
const MAX_TOTAL_INPUT_CHARS = 8000; // garde-fou rapide

export async function POST(req: Request) {
  try {
    // 1) Parse & validation
    const raw: unknown = await req.json();
    if (!isChatRequestBody(raw)) {
      return NextResponse.json(
        { error: 'RequÃªte invalide : messages manquants ou mal formÃ©s.' },
        { status: 400 },
      );
    }
    if (!API_KEY || !PROJECT) {
      console.error('[API ERROR] OPENAI_API_KEY / OPENAI_PROJECT_ID manquant(s).');
      return NextResponse.json({ error: 'Configuration serveur incomplÃ¨te.' }, { status: 500 });
    }

    // 2) Normalisation & limitations
    const limited = raw.messages.slice(-MAX_HISTORY).map((m) => ({
      ...m,
      text: m.text.trim(),
    }));

    const totalChars = limited.reduce((n, m) => n + m.text.length, 0);
    if (totalChars > MAX_TOTAL_INPUT_CHARS) {
      return NextResponse.json(
        { error: 'EntrÃ©e trop volumineuse. RÃ©duis un peu le contexte ğŸ«£' },
        { status: 400 },
      );
    }

    // 3) Construction du prompt pour OpenAI
    const systemMessage = {
      role: 'system' as const,
      content: `
Tu es un assistant voyage expert et chaleureux, spÃ©cialisÃ© au QuÃ©bec et au Canada.

ğŸ¯ Ta mission :
- Aider familles / campeurs / amoureux de nature & bouffe locale Ã  organiser leur voyage.
- Proposer destinations, itinÃ©raires, activitÃ©s, bons plans.
- Mettre en avant les contenus du site : blog, vidÃ©os, objets, planificateur.
- Si la destination correspond Ã  un article connu (ex. "tadoussac", "banff", "gaspÃ©sie"), ajoute des liens **valables** en Markdown :
  ğŸ“˜ Article : [Voir lâ€™article](/blog/NOM-DESTINATION)
  ğŸ¥ VidÃ©os : [Regarder les vidÃ©os](/videos#NOM-DESTINATION)
  ğŸ§³ Objets utiles : [Voir la liste](/objets)
  ğŸ—ºï¸ Planificateur : [Planifier mon voyage](/planificateur)
  ğŸ¨ HÃ´tels : [HÃ´tels Ã  NOM](https://www.booking.com/searchresults.html?city=xxx.fr.html)

ğŸ—£ï¸ Ton :
- Simple, amical, pro.
- Termine par une question utile :
  â†’ â€œTu prÃ©fÃ¨res une Ã©tape plus sauvage ou plutÃ´t gourmande ?â€
  â†’ â€œTu as une rÃ©gion ou un budget en tÃªte ?â€

ğŸ›‘ Ne donne jamais de lien qui ne mÃ¨ne Ã  rien.
ğŸ—¨ï¸ RÃ©ponds uniquement en franÃ§ais. Ã‰mojis OK avec modÃ©ration.
      `.trim(),
    };

    const openAiMessages: ReadonlyArray<{
      role: 'system' | 'user' | 'assistant';
      content: string;
    }> = [
      systemMessage,
      ...limited.map((m) => ({
        role: m.isUser ? ('user' as const) : ('assistant' as const),
        content: m.text,
      })),
    ];

    const body = {
      model: MODEL,
      temperature: TEMPERATURE,
      max_tokens: 800,
      messages: openAiMessages,
    } as const;

    // 4) Appel OpenAI avec timeout (AbortController)
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 25_000); // 25s max
    const res = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${API_KEY}`,
        'Content-Type': 'application/json',
        'OpenAI-Project': PROJECT,
      },
      body: JSON.stringify(body),
      signal: controller.signal,
    }).finally(() => clearTimeout(timeout));

    const dataU: unknown = await res.json();

    if (!res.ok) {
      const detail = isRecord(dataU) ? dataU : { message: 'RÃ©ponse OpenAI non conforme.' };
      console.error('[OpenAI ERROR]', detail);
      return NextResponse.json({ error: 'Erreur OpenAI', detail }, { status: 502 });
    }

    if (!isOpenAIResponse(dataU)) {
      console.error('[OpenAI ERROR] SchÃ©ma de rÃ©ponse inattendu:', dataU);
      return NextResponse.json({ error: 'RÃ©ponse OpenAI inattendue' }, { status: 502 });
    }

    const reply = extractOpenAIReply(dataU) ?? 'Je nâ€™ai pas compris, peux-tu reformuler ?';
    return NextResponse.json({ message: reply });
  } catch (err: unknown) {
    const msg = err instanceof Error ? err.message : 'Erreur inconnue';
    // AbortError (timeout) â†’ message plus clair
    if (msg.includes('The operation was aborted')) {
      return NextResponse.json(
        { error: 'Timeout OpenAI â€” rÃ©essaie dans un instant ğŸ™' },
        { status: 504 },
      );
    }
    console.error('[SERVER ERROR]', msg);
    return NextResponse.json({ error: 'Erreur serveur ou OpenAI' }, { status: 500 });
  }
}
